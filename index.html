<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Screenshot Analyzer</title>
    <style>
      body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
          sans-serif;
        background: #f8f9fa;
        margin: 0;
        padding: 2rem;
        min-height: 100vh;
      }

      .container {
        max-width: 1000px;
        margin: 0 auto;
        background: white;
        padding: 2rem;
        border-radius: 12px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
      }

      .upload-section {
        border: 2px dashed #e0e0e0;
        border-radius: 8px;
        padding: 2rem;
        text-align: center;
        margin-bottom: 2rem;
        transition: border-color 0.2s;
      }

      input[type="file"] {
        display: none;
      }

      .custom-upload {
        background: #007bff;
        color: white;
        padding: 0.75rem 1.5rem;
        border-radius: 6px;
        cursor: pointer;
        transition: background 0.2s;
        display: inline-block;
      }

      .custom-upload:hover {
        background: #0056b3;
      }

      table {
        width: 100%;
        border-collapse: collapse;
        margin-top: 2rem;
      }

      th,
      td {
        padding: 12px;
        text-align: left;
        border-bottom: 1px solid #e0e0e0;
      }

      th {
        background-color: #f8f9fa;
        font-weight: 500;
      }

      .button-group {
        display: flex;
        justify-content: space-between;
        margin-top: 1rem;
      }

      .download-btn,
      .clear-btn {
        padding: 0.75rem 1.5rem;
        border: none;
        border-radius: 6px;
        cursor: pointer;
        transition: background 0.2s;
        color: white;
      }

      .download-btn {
        background: #28a745;
      }

      .download-btn:hover {
        background: #218838;
      }

      .clear-btn {
        background: #dc3545;
      }

      .clear-btn:hover {
        background: #c82333;
      }

      .loading {
        display: none;
        margin: 1rem 0;
        color: #6c757d;
      }

      .status-log {
        margin-top: 1rem;
        background-color: #f8f9fa;
        border: 1px solid #e0e0e0;
        border-radius: 6px;
        padding: 1rem;
        font-family: monospace;
        max-height: 200px;
        overflow-y: auto;
        display: none;
      }

      .status-log pre {
        margin: 0;
        white-space: pre-wrap;
        word-break: break-all;
      }

      .debug-toggle {
        margin-top: 1rem;
        font-size: 0.85rem;
        color: #6c757d;
        cursor: pointer;
      }

      .debug-toggle:hover {
        text-decoration: underline;
      }
      .model-selection {
        margin-bottom: 1.5rem;
        padding: 1rem;
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        background-color: #fafafa;
      }

      .model-selection h3 {
        margin-top: 0;
        margin-bottom: 1rem;
        font-size: 1.1rem;
        color: #333;
      }

      .model-options {
        display: flex;
        flex-wrap: wrap;
        gap: 1rem;
      }

      .model-options label {
        display: flex;
        align-items: center;
        padding: 0.5rem 1rem;
        border: 1px solid #e0e0e0;
        border-radius: 6px;
        background-color: white;
        cursor: pointer;
        transition: all 0.2s;
      }

      .model-options label:hover {
        background-color: #f0f0f0;
      }

      .model-options input[type="radio"] {
        margin-right: 0.5rem;
      }

      .model-options input[type="radio"]:checked + span {
        font-weight: 500;
        color: #007bff;
      }

      .rate-limit-info {
        background: #e3f2fd;
        border: 1px solid #bbdefb;
        border-radius: 6px;
        padding: 1rem;
        margin-bottom: 1rem;
        font-size: 0.9rem;
        color: #1565c0;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>Screenshot Analyzer - Optimized</h1>

      <div class="rate-limit-info">
        <strong>Ultra-Safe Mode:</strong> After seeing 429 errors, this version
        uses maximum safety delays (4+ seconds between requests) to guarantee
        zero rate limits. Speed is sacrificed for 100% reliability.
      </div>

      <div class="upload-section">
        <input type="file" id="fileInput" accept="image/*" multiple />

        <label for="fileInput" class="custom-upload"> Upload Screenshot </label>
        <p style="margin-top: 1rem; color: #6c757d">(PNG, JPG supported)</p>
      </div>
      <div class="model-selection">
        <h3>Select AI Model</h3>
        <div class="model-options">
          <label>
            <input type="radio" name="model" value="gpt-4o-mini" checked />
            <span>GPT-4o Mini (OpenAI) - Recommended</span>
          </label>
          <label>
            <input type="radio" name="model" value="qwen/qwen-vl-plus" />
            <span>Qwen VL Plus (OpenRouter)</span>
          </label>
          <label>
            <input
              type="radio"
              name="model"
              value="google/gemma-3-12b-it:free"
            />
            <span>Gemma 3 12B (OpenRouter)</span>
          </label>
        </div>
      </div>
      <div class="button-group">
        <button class="clear-btn" id="clearBtn">Clear All</button>
        <button class="download-btn" id="downloadBtn">Download CSV</button>
      </div>
      <table>
        <thead>
          <tr>
            <th>Name</th>
            <th>Company</th>
            <th>Role</th>
            <th>Credentials</th>
          </tr>
        </thead>
        <tbody id="tableBody">
          <!-- Rows will be added dynamically -->
        </tbody>
      </table>

      <div class="loading" id="loading">Analyzing...</div>

      <div class="debug-toggle" id="debugToggle">Show Debug Console</div>
      <div class="status-log" id="statusLog">
        <pre id="statusText"></pre>
      </div>
    </div>

    <script>
      // Optimized rate limiting system
      let entries = [];
      const DB_NAME = "screenshotAnalyzerDB";
      const STORE_NAME = "entries";
      const BATCH_COUNTER_STORE = "batchCounters";

      // Ultra-conservative rate limiting configuration to prevent 429 errors
      const RATE_LIMIT_CONFIG = {
        // Much more conservative limits after seeing 429 errors
        "gpt-4o-mini": {
          maxConcurrent: 1, // Back to 1 concurrent - safest approach
          baseDelay: 4000, // 4 second minimum delay
          burstLimit: 2, // Only 2 quick requests allowed
          burstWindow: 120000, // 2 minute window
          minDelayAfterError: 15000, // 15 second delay after any error
        },
        "gpt-4o": {
          maxConcurrent: 1,
          baseDelay: 6000, // Even more conservative
          burstLimit: 1,
          burstWindow: 120000,
          minDelayAfterError: 20000,
        },
        default: {
          // For OpenRouter models
          maxConcurrent: 1,
          baseDelay: 5000,
          burstLimit: 2,
          burstWindow: 120000,
          minDelayAfterError: 18000,
        },
      };

      // Rate limiting state
      let activeRequests = 0;
      let requestQueue = [];
      let lastRequestTime = 0;
      let burstCount = 0;
      let burstWindowStart = 0;
      let consecutiveErrors = 0;
      let adaptiveDelayMultiplier = 1;

      // Get current rate limit config based on selected model
      function getCurrentConfig() {
        const selectedModel = document.querySelector(
          'input[name="model"]:checked'
        ).value;
        return RATE_LIMIT_CONFIG[selectedModel] || RATE_LIMIT_CONFIG["default"];
      }

      // Enhanced delay calculation with error-based backoff
      function calculateDelay() {
        const config = getCurrentConfig();
        const now = Date.now();

        // If we've had recent errors, use much longer delays
        if (consecutiveErrors > 0) {
          const errorMultiplier = Math.min(5, Math.pow(2, consecutiveErrors)); // Exponential backoff
          const errorDelay = config.minDelayAfterError * errorMultiplier;
          logStatus(
            `Error-based delay: ${
              errorDelay / 1000
            }s (${consecutiveErrors} consecutive errors)`
          );
          return errorDelay;
        }

        // Reset burst counter if window expired
        if (now - burstWindowStart > config.burstWindow) {
          burstCount = 0;
          burstWindowStart = now;
          logStatus("Burst window reset");
        }

        // Even for burst requests, use minimum delay to be safe
        if (burstCount < config.burstLimit) {
          const burstDelay = Math.max(2000, config.baseDelay * 0.5); // Minimum 2 seconds even in burst
          logStatus(
            `Burst request ${burstCount + 1}/${config.burstLimit} - delay: ${
              burstDelay / 1000
            }s`
          );
          return burstDelay;
        }

        // Regular delay with adaptive multiplier
        const baseDelay = config.baseDelay * adaptiveDelayMultiplier;
        const timeSinceLastRequest = now - lastRequestTime;
        const calculatedDelay = Math.max(0, baseDelay - timeSinceLastRequest);

        logStatus(
          `Regular delay: ${
            calculatedDelay / 1000
          }s (multiplier: ${adaptiveDelayMultiplier}x)`
        );
        return calculatedDelay;
      }

      // Enhanced request scheduler
      async function scheduleRequest(requestFn) {
        return new Promise((resolve, reject) => {
          requestQueue.push({ requestFn, resolve, reject });
          processQueue();
        });
      }

      async function processQueue() {
        const config = getCurrentConfig();

        if (
          activeRequests >= config.maxConcurrent ||
          requestQueue.length === 0
        ) {
          return;
        }

        const { requestFn, resolve, reject } = requestQueue.shift();
        activeRequests++;

        try {
          const delay = calculateDelay();

          if (delay > 0) {
            logStatus(
              `Smart delay: ${delay}ms (${activeRequests} active, ${requestQueue.length} queued)`
            );
            await new Promise((r) => setTimeout(r, delay));
          }

          lastRequestTime = Date.now();
          burstCount++;

          const result = await requestFn();

          // Success - gradually reduce adaptive delay and reset error count
          consecutiveErrors = 0;
          if (adaptiveDelayMultiplier > 1) {
            adaptiveDelayMultiplier = Math.max(
              1,
              adaptiveDelayMultiplier * 0.8
            );
            logStatus(
              `Success! Reduced delay multiplier to ${adaptiveDelayMultiplier}x`
            );
          }

          resolve(result);
        } catch (error) {
          // Handle errors with aggressive backoff
          consecutiveErrors++;

          if (
            error.message.includes("429") ||
            error.message.includes("rate limit")
          ) {
            // Much more aggressive rate limit response
            adaptiveDelayMultiplier = Math.min(
              8,
              adaptiveDelayMultiplier * 2.5
            );
            logStatus(
              `🚨 RATE LIMIT! Increased delay multiplier to ${adaptiveDelayMultiplier}x. Consecutive errors: ${consecutiveErrors}`,
              true
            );

            // Reset burst counter to prevent further fast requests
            burstCount = config.burstLimit;
          } else {
            // For other errors, moderate increase
            adaptiveDelayMultiplier = Math.min(
              4,
              adaptiveDelayMultiplier * 1.3
            );
            logStatus(
              `Error detected. Delay multiplier: ${adaptiveDelayMultiplier}x`,
              true
            );
          }

          reject(error);
        } finally {
          activeRequests--;
          // Much longer delay before processing next request after any request
          setTimeout(processQueue, 500);
        }
      }

      // Improved retry logic with smarter backoff
      async function processImageFileWithRetry(file, db, batchInfo) {
        const fileId = `file-${Date.now()}-${Math.floor(Math.random() * 1000)}`;
        const maxRetries = 3;
        const selectedModel = document.querySelector(
          'input[name="model"]:checked'
        ).value;

        logStatus(`Processing ${file.name} with ${selectedModel}`);

        // Add placeholder
        const placeholderEntry = {
          name: `Analyzing ${file.name}...`,
          company: "In progress",
          role: "-",
          credentials: "-",
          timestamp: new Date().toISOString(),
          isPlaceholder: true,
          fileId: fileId,
          batchName: batchInfo.fileName,
          batchDisplayName: batchInfo.displayName,
        };

        entries.push(placeholderEntry);
        updateTable();

        // Smart retry with exponential backoff
        for (let attempt = 0; attempt < maxRetries; attempt++) {
          try {
            const result = await processImageFileOnce(
              file,
              fileId,
              batchInfo,
              selectedModel
            );

            // Success! Remove placeholder and add results
            entries = entries.filter((entry) => entry.fileId !== fileId);
            result.forEach((entry) => {
              entry.batchName = batchInfo.fileName;
              entry.batchDisplayName = batchInfo.displayName;
            });

            entries = [...entries, ...result];
            updateTable();
            await saveEntries(db);

            return result.length;
          } catch (error) {
            const isRateLimit =
              error.message.includes("429") ||
              error.message.includes("rate limit");
            const isLastAttempt = attempt === maxRetries - 1;

            if (isRateLimit && !isLastAttempt) {
              // Much longer backoff for rate limits - aggressive approach
              const delays = [10000, 30000, 60000]; // 10s, 30s, 60s
              const delay = delays[attempt] || 120000; // 2 minutes for final attempts

              logStatus(
                `🚨 Rate limit on ${file.name}. Waiting ${
                  delay / 1000
                }s before retry ${attempt + 2}/${maxRetries}...`,
                true
              );

              // Also increase global delay multiplier
              adaptiveDelayMultiplier = Math.min(
                8,
                adaptiveDelayMultiplier * 2
              );
              consecutiveErrors++;

              await new Promise((resolve) => setTimeout(resolve, delay));
              continue;
            }

            // Failed permanently
            logStatus(
              `Failed ${file.name} after ${attempt + 1} attempts: ${
                error.message
              }`,
              true
            );

            entries = entries.filter((entry) => entry.fileId !== fileId);
            const errorEntry = {
              name: `Failed: ${file.name}`,
              company: "Error",
              role:
                error.message.substring(0, 30) +
                (error.message.length > 30 ? "..." : ""),
              credentials: `${attempt + 1} attempts`,
              timestamp: new Date().toISOString(),
              isError: true,
              batchName: batchInfo.fileName,
              batchDisplayName: batchInfo.displayName,
            };

            entries.push(errorEntry);
            updateTable();
            await saveEntries(db);
            return 0;
          }
        }

        return 0;
      }

      // Debug logging function
      function logStatus(message, isError = false) {
        const statusText = document.getElementById("statusText");
        const timestamp = new Date().toLocaleTimeString();
        const logEntry = `[${timestamp}] ${
          isError ? "❌ ERROR: " : "✓ "
        } ${message}`;
        statusText.innerHTML += logEntry + "\n";
        statusText.scrollTop = statusText.scrollHeight;
        console.log(logEntry);

        if (isError) {
          document.getElementById("statusLog").style.display = "block";
          document.getElementById("debugToggle").textContent =
            "Hide Debug Console";
        }
      }

      // Initialize IndexedDB
      function initDB() {
        return new Promise((resolve, reject) => {
          if (!window.indexedDB) {
            logStatus(
              "Your browser doesn't support IndexedDB. Using local storage instead."
            );
            resolve(null);
            return;
          }

          const request = indexedDB.open(DB_NAME, 2);

          request.onerror = (event) => {
            logStatus("IndexedDB error: " + event.target.error, true);
            resolve(null);
          };

          request.onupgradeneeded = (event) => {
            const db = event.target.result;
            if (!db.objectStoreNames.contains(STORE_NAME)) {
              db.createObjectStore(STORE_NAME, {
                keyPath: "id",
                autoIncrement: true,
              });
            }
            if (!db.objectStoreNames.contains(BATCH_COUNTER_STORE)) {
              db.createObjectStore(BATCH_COUNTER_STORE, {
                keyPath: "date",
              });
            }
          };

          request.onsuccess = (event) => {
            logStatus("Database initialized successfully");
            resolve(event.target.result);
          };
        });
      }

      // Generate batch name for current upload
      async function generateBatchName(db) {
        const now = new Date();
        const day = now.getDate().toString().padStart(2, "0");
        const month = now.toLocaleString("en-US", { month: "short" });
        const year = now.getFullYear();
        const dateStr = `${day}${month}${year}`;

        let batchNumber = 1;

        try {
          if (db) {
            const transaction = db.transaction(
              [BATCH_COUNTER_STORE],
              "readwrite"
            );
            const store = transaction.objectStore(BATCH_COUNTER_STORE);
            const currentDate = now.toISOString().split("T")[0];
            const request = store.get(currentDate);

            await new Promise((resolve, reject) => {
              request.onsuccess = (event) => {
                const result = event.target.result;
                if (result) {
                  batchNumber = result.counter + 1;
                  store.put({ date: currentDate, counter: batchNumber });
                } else {
                  store.add({ date: currentDate, counter: 1 });
                }
                resolve();
              };

              request.onerror = (event) => {
                logStatus(
                  "Error getting batch counter: " + event.target.error,
                  true
                );
                reject(event.target.error);
              };
            });
          } else {
            const storedCounters = localStorage.getItem("batchCounters");
            if (storedCounters) {
              const counters = JSON.parse(storedCounters);
              const today = now.toISOString().split("T")[0];
              if (counters[today]) {
                batchNumber = counters[today] + 1;
              }
              counters[today] = batchNumber;
              localStorage.setItem("batchCounters", JSON.stringify(counters));
            } else {
              const counters = {};
              const today = now.toISOString().split("T")[0];
              counters[today] = 1;
              localStorage.setItem("batchCounters", JSON.stringify(counters));
            }
          }
        } catch (error) {
          logStatus("Error generating batch name: " + error.message, true);
        }

        const readableMonth = now.toLocaleString("en-US", { month: "long" });
        const readableDateStr = `${readableMonth} ${day}, ${year} - ${batchNumber}`;

        return {
          fileName: `${dateStr}-${batchNumber}`,
          displayName: readableDateStr,
        };
      }

      // Save entries to storage
      async function saveEntries(db) {
        if (db) {
          const transaction = db.transaction([STORE_NAME], "readwrite");
          const store = transaction.objectStore(STORE_NAME);
          store.clear();
          entries.forEach((entry) => {
            store.add(entry);
          });
          logStatus(`Saved ${entries.length} entries to IndexedDB`);
        } else {
          localStorage.setItem(
            "screenshotAnalyzerEntries",
            JSON.stringify(entries)
          );
          logStatus(`Saved ${entries.length} entries to localStorage`);
        }
      }

      // Load entries from storage
      async function loadEntries(db) {
        return new Promise((resolve, reject) => {
          if (db) {
            const transaction = db.transaction([STORE_NAME], "readonly");
            const store = transaction.objectStore(STORE_NAME);
            const request = store.getAll();

            request.onsuccess = () => {
              logStatus(
                `Loaded ${
                  request.result ? request.result.length : 0
                } entries from IndexedDB`
              );
              resolve(request.result || []);
            };

            request.onerror = (event) => {
              logStatus("Error loading entries: " + event.target.error, true);
              resolve([]);
            };
          } else {
            const savedEntries = localStorage.getItem(
              "screenshotAnalyzerEntries"
            );
            const parsed = savedEntries ? JSON.parse(savedEntries) : [];
            logStatus(`Loaded ${parsed.length} entries from localStorage`);
            resolve(parsed);
          }
        });
      }

      // Parse the AI response for multiple people
      function parseMultiplePersons(text) {
        logStatus("Parsing AI response");
        const personBlocks = text.split(/\n\s*\n/);
        logStatus(`Found ${personBlocks.length} person blocks in response`);

        const results = personBlocks
          .map((block) => {
            const result = block.split("\n").reduce((acc, line) => {
              if (line.includes(": ")) {
                const [key, value] = line.split(": ").map((s) => s.trim());
                acc[key.toLowerCase()] = value;
              }
              return acc;
            }, {});

            return {
              name: result.name || "N/A",
              company: result.company || "N/A",
              role: result.role || "N/A",
              credentials: result.credentials || "N/A",
              timestamp: new Date().toISOString(),
            };
          })
          .filter(
            (person) => person.name !== "N/A" || person.company !== "N/A"
          );

        logStatus(
          `Successfully parsed ${results.length} people from the response`
        );
        return results;
      }

      // Update the table with entries
      function updateTable() {
        const tableBody = document.getElementById("tableBody");
        tableBody.innerHTML = entries
          .map(
            (entry, index) => `
    <tr id="entry-${index}">
      <td>${entry.name}</td>
      <td>${entry.company}</td>
      <td>${entry.role}</td>
      <td>${entry.credentials}</td>
    </tr>
  `
          )
          .join("");
        logStatus(`Updated table with ${entries.length} entries`);
      }

      // Process single image file
      async function processImageFileOnce(
        file,
        fileId,
        batchInfo,
        selectedModel
      ) {
        const base64 = await new Promise((resolve, reject) => {
          const reader = new FileReader();
          reader.readAsDataURL(file);
          reader.onload = () => resolve(reader.result);
          reader.onerror = (error) => reject(error);
        });

        logStatus(`Sending API request for ${fileId}`);

        const response = await fetch("/.netlify/functions/analyze-image", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify({
            imageBase64: base64,
            filename: file.name,
            selectedModel: selectedModel,
          }),
        });

        if (!response.ok) {
          const errorText = await response.text();
          const error = new Error(
            `API Error: ${response.status} ${response.statusText} - ${errorText}`
          );
          error.status = response.status;
          throw error;
        }

        const data = await response.json();

        if (data.error) {
          throw new Error(`API Error: ${data.error}`);
        }

        const newEntries = parseMultiplePersons(data.text);
        logStatus(`Extracted ${newEntries.length} people from ${fileId}`);

        return newEntries;
      }

      // Optimized batch processing
      async function processFiles(files, db) {
        const fileArray = Array.from(files);
        const total = fileArray.length;
        const loading = document.getElementById("loading");

        const batchInfo = await generateBatchName(db);
        logStatus(
          `Starting optimized batch: ${batchInfo.displayName} (${total} files)`
        );

        document.getElementById(
          "downloadBtn"
        ).textContent = `Download CSV (${batchInfo.displayName})`;

        loading.textContent = `Processing 0/${total} files...`;
        loading.style.display = "block";

        let completed = 0;
        let totalEntries = 0;

        // Reset rate limiting state for new batch - but keep it conservative
        burstCount = 0;
        burstWindowStart = Date.now();
        // Don't reset consecutiveErrors or adaptiveDelayMultiplier - keep learning from previous errors

        logStatus(
          `🔧 Starting ultra-safe batch processing: ${batchInfo.displayName}`
        );
        logStatus(
          `Current settings: ${getCurrentConfig().maxConcurrent} concurrent, ${
            getCurrentConfig().baseDelay / 1000
          }s base delay, ${adaptiveDelayMultiplier}x multiplier`
        );

        // Process files with smart concurrency
        const promises = fileArray.map(async (file, index) => {
          const entryCount = await scheduleRequest(() =>
            processImageFileWithRetry(file, db, batchInfo)
          );

          completed++;
          totalEntries += entryCount;
          loading.textContent = `Processing ${completed}/${total} files... (${totalEntries} entries found)`;
          logStatus(
            `Completed ${completed}/${total} files (${totalEntries} total entries)`
          );

          return entryCount;
        });

        const results = await Promise.all(promises);
        totalEntries = results.reduce((sum, count) => sum + count, 0);

        loading.style.display = "none";
        logStatus(
          `🎉 Batch complete! Processed ${total} files, extracted ${totalEntries} entries`
        );

        window.currentBatchName = batchInfo.fileName;
        window.currentBatchDisplayName = batchInfo.displayName;
      }

      // Download entries as CSV
      function downloadCSV() {
        const fileName =
          window.currentBatchName ||
          `export-${new Date().toISOString().slice(0, 10)}`;
        const displayName =
          window.currentBatchDisplayName ||
          `Export ${new Date().toLocaleDateString()}`;

        const dataEntries = entries.filter(
          (entry) =>
            !entry.isPlaceholder &&
            !entry.isError &&
            (!window.currentBatchName ||
              entry.batchName === window.currentBatchName)
        );

        const headers = ["Name", "Company", "Role", "Credentials", "Batch"];
        const csvContent = [
          headers.join(","),
          ...dataEntries.map((entry) =>
            [
              `"${(entry.name || "").replace(/"/g, '""')}"`,
              `"${(entry.company || "").replace(/"/g, '""')}"`,
              `"${(entry.role || "").replace(/"/g, '""')}"`,
              `"${(entry.credentials || "").replace(/"/g, '""')}"`,
              `"${(entry.batchDisplayName || entry.batchName || "").replace(
                /"/g,
                '""'
              )}"`,
            ].join(",")
          ),
        ].join("\n");

        const blob = new Blob([csvContent], {
          type: "text/csv;charset=utf-8;",
        });
        const url = URL.createObjectURL(blob);
        const link = document.createElement("a");
        link.setAttribute("href", url);
        link.setAttribute("download", `${fileName}.csv`);
        link.style.visibility = "hidden";
        document.body.appendChild(link);
        link.click();
        document.body.removeChild(link);
        logStatus(
          `Downloaded CSV: ${fileName}.csv with ${dataEntries.length} entries`
        );
      }

      function resetFileInput() {
        document.getElementById("fileInput").value = "";
        logStatus("Reset file input after model change");
      }

      // Initialize the application
      async function init() {
        logStatus("Initializing optimized screenshot analyzer");
        const db = await initDB();
        entries = await loadEntries(db);
        updateTable();

        document
          .getElementById("downloadBtn")
          .addEventListener("click", downloadCSV);

        document
          .getElementById("clearBtn")
          .addEventListener("click", async () => {
            entries = [];
            updateTable();
            await saveEntries(db);
            document.getElementById("downloadBtn").textContent = "Download CSV";
            window.currentBatchName = null;
            window.currentBatchDisplayName = null;
            logStatus("Cleared all entries");
          });

        document.getElementById("debugToggle").addEventListener("click", () => {
          const statusLog = document.getElementById("statusLog");
          const debugToggle = document.getElementById("debugToggle");
          if (statusLog.style.display === "none" || !statusLog.style.display) {
            statusLog.style.display = "block";
            debugToggle.textContent = "Hide Debug Console";
          } else {
            statusLog.style.display = "none";
            debugToggle.textContent = "Show Debug Console";
          }
        });

        document
          .getElementById("fileInput")
          .addEventListener("change", async (e) => {
            const files = e.target.files;
            if (!files.length) {
              logStatus("No files selected", true);
              return;
            }

            await processFiles(files, db);
          });

        const modelRadios = document.querySelectorAll('input[name="model"]');
        modelRadios.forEach((radio) => {
          radio.addEventListener("change", () => {
            logStatus(`Model changed to: ${radio.value}`);
            resetFileInput();
            // Reset rate limiting state when model changes
            adaptiveDelayMultiplier = 1;
            consecutiveErrors = 0;
          });
        });

        logStatus(
          `✅ Application ready - ULTRA-SAFE mode to prevent 429 errors!`
        );
        logStatus(
          `⚠️  This version prioritizes zero rate limits over speed. Each image will wait 4+ seconds.`
        );
      }

      window.addEventListener("DOMContentLoaded", init);
    </script>
  </body>
</html>
